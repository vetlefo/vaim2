services:
  llm-service:
    build:
      context: .
      target: production
    container_name: llm-service
    ports:
      - "3003:3003"  # API
      - "9464:9464"  # Metrics
      - "3004:3004"  # WebSocket
    environment:
      - NODE_ENV=development
      - PORT=3003
      - WS_PORT=3004
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=
      - REDIS_DB=0
      - JWT_SECRET=your-jwt-secret
    depends_on:
      - redis
    networks:
      - llm-network
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3003/api/v1/monitoring/health || exit 1"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 30s

  redis:
    image: redis:7-alpine
    container_name: llm-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    networks:
      - llm-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 10s

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: llm-redis-commander
    ports:
      - "8081:8081"
    environment:
      - REDIS_HOSTS=local:redis:6379
    depends_on:
      - redis
    networks:
      - llm-network

networks:
  llm-network:
    driver: bridge

volumes:
  redis-data:
    driver: local